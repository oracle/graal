Usage: polybench [OPTION]... --path [FILE]

This launcher is designed for benchmarking Truffle languages. 

It repeatedly executes the source file specified by its path, 
whereas the number of warmup and hot iterations can be specified 
either explicitly or determined via interop from the evaluated source value 
by reading or executing members iterations and warmupIterations.

The launcher generates a structured output containing information 
on individual iterations as well as the benchmark summary.

The following options are accepted:

  --path <script>

  --class-name <class>     
       The class name of an Espresso benchmark inside the jar specified 
       by path (only relevant when executing Java workloads).

  --mode [interpreter | standard]
       Specified the mode which the benchmark will be running in. (default standard)

  --metric [peak-time | compilation-time | partial-evaluation-time | one-shot | 
            metaspace-memory | application-memory | none] (default peak-time)
  
  -w <N>
       The number of warmup iterations

  -i <N>
       The number of hot iterations

  --eval-source-only
       Indicates that the source file will be evaluated only, and the benchmark 
       execution will be skipped. It can be useful for parsing time benchmarking 
       or for using the debug auxiliary engine cache. N.B. This option can also 
       be specified for each run in a multi-context benchmarking. See below.

Multi-context benchmarking

This launcher allows for multi-context benchmarking consisting of several consecutive 
benchmark runs. Each run is executed using a new context instance, while all contexts 
can share a single engine. A multi-context benchmarking can be configured using the 
following options:

  --multi-context-runs=<N>
       The number of runs

  --shared-engine=[true | false]
       Indicates whether the contexts will share a single engine. If false, the context 
       of each run will have a separate engine, otherwise all contexts will share a single 
       engine. It is possible to specify different arguments for each run. The pattern of a 
       run specific argument is:

 <arg_name>.<run>=<value>
 
 
Examples:
 
  A single run with 5 warmup and 10 hot iterations
     polybench --path bench.so -w 5 -i 10
 
  Two runs with 5 warmup and 10 hot iterations each (no shared engine)
     polybench --path bench.so --multi-context-runs=2 -w 5 -i 10
 
  Two runs with 5 warmup and 10 hot iterations each with a shared engine
     polybench --path bench.so --multi-context-runs=2 --shared-engine=true -w 5 -i 10
 
  Storing the auxiliary engine cache and skipping the benchmark
     polybench --path bench.so --eval-source-only=true --experimental-options 
               --engine.CacheStore=test.image --engine.CacheCompile=aot
 
  Loading the auxiliary engine cache and running the benchmark
     polybench --path bench.so --experimental-options 
               --engine.CacheLoad=test.image -w 0 -i 10
 
  Using the debug engine cache. The first run only evaluates the source and stores the debug 
  engine cache, while the second run executes the benchmark with the cache.
     polybench --path bench.so --multi-context-runs=2 --eval-source-only.0=true 
               -w 0 -i 10 --experimental-options --engine.DebugCacheCompile.0=aot 
               --engine.DebugCacheStore.0=true --engine.DebugCacheStore.1=false --engine.DebugCacheLoad.1=true
 
  Reporting the source evaluation time only for 10 runs
     polybench --path bench.so --multi-context-runs=10 --eval-source-only=true
 
 